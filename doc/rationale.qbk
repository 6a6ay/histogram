[section Rationale]

This library was designed based on a decade of experience collected in working with big data, more precisely in the field of particle physics and astroparticle physics.

Everything should be guided by principles.

* "Do one thing and do it well", Doug McIlroy
* The [@https://www.python.org/dev/peps/pep-0020 Zen of Python] (also applies to other languages).

The implementation is build on advice from C++ experts, like Bjarne Stroustrup, Scott Meyers, Herb Sutter, and Andrei Alexandrescu, and Chandler Carruth.

[section Static and dynamic histograms]

Histograms have a number of axes. An axis defines which range of input values is mapped to which bin. The number of axes may be known at compile time or runtime, depending on how the library is used. The library supports several [link histogram.rationale.axis_types axis specializations]. The axis type can also be known at compile time or runtime.

The library therefore provides two histogram implementations, a [classref boost::histogram::static_histogram static] and [classref boost::histogram::dynamic_histogram dynamic] one. The static implementation is faster if the number of axes is small (see [link histogram.benchmarks benchmark]), because compiler is able to inline more code. The static approach does not work when you want to create histograms at runtime, for example, from Python. Therefore a second implementation is included in which the number of axes and their types may be defined at runtime.

[endsect]

[section Python support]

Python is a great language for data analysis and very popular in the data science community. Thus, the library includes Python bindings. The histogram is usable as an interface between a complex simulation or data-storage system written in C++ and data-analysis/plotting in Python. Users are able to define the histogram in Python, let it be filled on the C++ side, and then get it back for further data analysis or plotting.

Data analysis in Python is Numpy-based, so Numpy support is included. If number of dimensions is larger than one, this implementation is faster than the equivalent Numpy functions (while being more flexible), see [link histogram.benchmarks benchmark].

[note
The Python and C++ interface try to be consistent, but sometimes Python offers more elegant and pythonic ways of implementing things. Where possible, the more pythonic interface is used.

Properties: Getter/setter-like functions are wrapped as properties.

Keyword-based parameters: C++ member functions `fill(...)` and `wfill(...)` are wrapped by the single Python member function `fill(...)` with an optional keyword parameter `w` to pass a weight.
]

[endsect]

[section Axis types]

An axis defines which range of input values is mapped to which bin. The library encapsulates the logic in an axis type. The library comes with five axis types, which implement different specializations.

* [classref boost::histogram::regular_axis] sorts real numbers into bins with equal width.
* [classref boost::histogram::variable_axis] sorts real numbers into bins with varying width.
* [classref boost::histogram::polar_axis] is a specialization for angles, which wrap around after 2pi.
* [classref boost::histogram::integer_axis] is a specialization for covering a continuous range of integers.
* [classref boost::histogram::category_axis] is a specialization for categorial data.

Library users can create their own axis classes and use them with the library, by providing an implementation compatible with the axis concept.

[endsect]

[section Overflow and underflow bins]

The library supports extra bins that count values with fall below or above the range covered by the axis. These extra bins are called overflow and underflow bins, respectively. The extra bins can be turned off individually for each axis at runtime to conserve memory, but are turned on by default. The extra bins do not disturb normal bin counting. On an axis with `n` bins, the first bin has the index `0`, the last bin `n-1`, while the under- and overflow bins are accessible at the indices `-1` and `n`, respectively.

Under- and overflow bins are useful in one-dimensional histograms, and nearly essential in multi-dimensional histograms.

* No loss: The total sum over all bins is equal to the number of times `fill(...)` was called. Even NaN values are counted (they end up in the underflow bin by convention).
* Diagnosis: Unexpected extreme values will show up in the extra bins, which otherwise might be overlooked.
* Projections: In multi-dimensional histograms, an extreme value along one axis may be paired with a normal value along another axis. If under- and overflow bins are missing, the whole pair is lost. This distorts the histogram even along the axis where the value was in range. The extra bins allow one to project (projecting means summing up along the other axes) the histogram to any axis and get the same result as if one had filled a histogram with only that axis.

[endsect]

[section Performance and memory-efficiency of count storage]

Dense storage in memory is a must for high performance. Unfortunately, the [@https://en.wikipedia.org/wiki/Curse_of_dimensionality curse of dimensionality] quickly become a problem as the number of dimensions grows, leading to an exponentially growing number of bins. High-dimensional histograms can consume GBs of memory.

Fortunately, having many dimensions typically reduces the number of counts per bin, since counts are spread over many dimensions. This suggests an adaptive solution: start by allocating a minimum amount memory for a bin cell, and only grow the cell size if the cell would overflow otherwise.

This strategy is implemented by the default `adaptive_storage` class. It starts with the smallest integer of 1 byte per cell, and increases the cell size up to 8 byte. When even that is not enough, the integers are replaced by the [@boost:/libs/multiprecision/index.html Boost.Multiprecision] type `cpp_int`, whose capacity is limited only by available memory. In other words, a `std::vector` keeps the size of the stored type constant, but grows to hold a larger number of elements. The `adaptive_storage` does the opposite.

It turns out that even low dimensional histograms profit from this scheme, because a small storage size also reduces cache-misses and page reloads. This leads to better performance, despite the extra instructions needed to implement the polymorphic nature of the adaptive storage.

[endsect]

[section Weighted counts and variance estimates]

A histogram categorizes and counts, so the natural choice for the data type of the counts are integers. However, in particle physics, histograms are also often filled with weighted events, for example, to make sure that two histograms look the same in one variable, while the distribution of another, correlated variable is a subject of study.

The histogram can be filled with either weighted or unweighted counts. In the weighted case, the sum of weights is stored. The histogram provides a variance estimate is both cases. In the unweighted case, the estimate is computed from the count itself, using Poisson-theory. In the weighted case, the sum of squared weights is stored alongside the sum of weights, and used to compute a variance estimate.

[endsect]

[section Serialization]

Serialization is implemented using [@boost:/libs/serialization/index.html Boost.Serialization]. Pickling in Python is implemented based on the C++ serialization code. In the current implementation, the pickled stream is *not* portable, since it uses `boost::archive::binary_archive`. It would be great to switch to a portable binary representation in the future, when that becomes available.

[endsect]

[endsect]